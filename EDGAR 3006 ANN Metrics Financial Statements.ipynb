{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "var_CF = \"CF\"\n",
    "var_BS = \"BS\"\n",
    "var_IS = \"IS\"\n",
    "var_FS = var_IS\n",
    "\n",
    "\n",
    "\n",
    "folder_mai = \"edgarfiles/\"\n",
    "folder_pas = \"common files\"\n",
    "folder_fel = \"this folder has the quarterly and annual files\"\n",
    "folder_mai = \"common files are here\"\n",
    "folder_ann = \"this folder has three subfodler CF, BS, IS for the three financial statements\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get all Entries\n",
    "df_col_types = {\"sic\":str,\"cik\":str,\"fy\":str,\"qtrs\":str,\"ffy\":str,\"line\":str}\n",
    "df_ANNUAL = pd.read_csv((folder_fel+\"ANNUAL ALL.csv.zip\"),dtype=df_col_types)\n",
    "df_ANNUAL.drop([\"Unnamed: 0\"],axis=1,inplace=True)\n",
    "df_ANNUAL[\"tag\"] = df_ANNUAL[\"tag\"].str.upper()\n",
    "print(len(df_ANNUAL))\n",
    "\n",
    "df_currency = pd.read_excel((folder_mai+\"Currency Data.xlsx\"),sheet_name=\"subset\")\n",
    "\n",
    "# GET ALL TAGS\n",
    "df_all_tags = pd.read_excel((folder_mai+\"Tags and Stats.xlsx\"),sheet_name=\"Tag List\")\n",
    "df_all_tags.sort_values(by=[\"stmt\",\"metric\",\"tag_order\"],ascending=True,inplace=True)\n",
    "print(len(df_all_tags))\n",
    "\n",
    "# GET THE INDUSTRY AND THE SECTOR\n",
    "df_col_types = {\"sic\":str,\"cik\":str,\"fy\":str,\"qtrs\":str}\n",
    "df_cik_sic_align = pd.read_csv((folder_mai+\"cik_sic_align.csv\"),dtype=df_col_types)\n",
    "df_sic_data = df_cik_sic_align[[\"sic\",\"Office\",\"Industry Title\"]] \n",
    "df_sic_data.drop_duplicates(subset=\"sic\",inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data of a Single Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_co_name = \"SALES\"\n",
    "df_ANNUAL_temp = df_ANNUAL.copy()\n",
    "df_co_data = df_ANNUAL_temp[df_ANNUAL_temp[\"name\"].str.contains(var_co_name)]\n",
    "df_ANNUAL_temp = pd.DataFrame()\n",
    "df_co_data.drop_duplicates(subset=[\"name\"],inplace=True)\n",
    "df_co_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data of the Foreign company \n",
    "var_co_name = \"SFDC\"\n",
    "var_cik = \"1108524\"\n",
    "df_ANNUAL_temp = df_ANNUAL.copy()\n",
    "df_co = df_ANNUAL_temp[df_ANNUAL_temp[\"cik\"].str.contains(var_cik)]\n",
    "df_ANNUAL_temp = pd.DataFrame()\n",
    "print(len(df_co))\n",
    "df_co.to_csv((folder_cos+var_co_name+\" \"+var_cik+\" ANNUAL.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Statement Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income Statement\n",
    "var_FS = var_IS\n",
    "get_financial_statement_elements(var_FS)\n",
    "\n",
    "var_FS = var_BS\n",
    "get_financial_statement_elements(var_FS)\n",
    "\n",
    "var_FS = var_CF\n",
    "get_financial_statement_elements(var_FS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_financial_statement_elements(var_FS):\n",
    "    # GET METRICs \n",
    "    ls_met_tags = pd.unique(df_all_tags[\"metric\"][(df_all_tags[\"stmt\"] == var_FS)])\n",
    "\n",
    "#df_all_tags_copy = df_all_tags.copy()\n",
    "    counter_met = 0\n",
    "\n",
    "    while counter_met < len(ls_met_tags):\n",
    "\n",
    "    # GET RELEVANT TAGS    \n",
    "        df_rel_tags = df_all_tags[(df_all_tags[\"metric\"] == ls_met_tags[counter_met])&((df_all_tags[\"stmt\"] == var_FS))]\n",
    "\n",
    "        df_rel_tags.drop_duplicates(inplace=True)\n",
    "        df_rel_tags = pd.DataFrame(df_rel_tags)\n",
    "        print((\"Tags in Metric \"+ls_met_tags[counter_met]+\" are \"+np.str(len(df_rel_tags))))\n",
    "\n",
    "    # PARE DOWN THE FINANCIAL STATEMENT DATA TO ONLY THOSE TAGS THAT ARE RELEVANT\n",
    "        df_ANNUAL_temp = df_ANNUAL.copy()\n",
    "        \n",
    "        if var_FS == var_BS:\n",
    "            df_ANNUAL_rel = df_ANNUAL_temp[(df_ANNUAL_temp[\"stmt\"] == var_FS)\n",
    "                                           &(df_ANNUAL_temp[\"tag\"].isin(df_rel_tags[\"tag\"]))]\n",
    "        else:\n",
    "            df_ANNUAL_rel = df_ANNUAL_temp[(df_ANNUAL_temp[\"stmt\"] == var_FS) \n",
    "                                       &(df_ANNUAL_temp[\"tag\"].isin(df_rel_tags[\"tag\"]))\n",
    "                                   &(df_ANNUAL_temp[\"qtrs\"] == \"4\")]\n",
    "\n",
    "        print((\"Entries with \"+ls_met_tags[counter_met]+\" relevant tags are \"+np.str(len(df_ANNUAL_rel))))\n",
    "\n",
    "        ls_rel_tags = pd.unique(df_rel_tags[\"tag\"])\n",
    "\n",
    "        df_ANNUAL_temp = df_ANNUAL_rel.copy()\n",
    "        df_rel_cos = df_ANNUAL_temp[[\"cfy\"]]\n",
    "        df_rel_cos.drop_duplicates(subset=[\"cfy\"],inplace=True)\n",
    "        df_ANNUAL_temp = pd.DataFrame()\n",
    "        df_rel_cos_temp = df_rel_cos.copy()\n",
    "        print((\"Number of Relevant Co-FY Combos \"+np.str(len(df_rel_cos_temp))))\n",
    "\n",
    "        # Create a copy of the relevant entries\n",
    "        df_ANNUAL_rcop = df_ANNUAL_rel.copy()\n",
    "\n",
    "        df_entries_temp = pd.DataFrame()\n",
    "        df_cosfy_tagfound = pd.DataFrame()\n",
    "        df_cosfy_alltagfound = pd.DataFrame()\n",
    "        df_cf_list = pd.DataFrame()\n",
    "        counter_tag = 0\n",
    "\n",
    "        while counter_tag < len(ls_rel_tags):\n",
    "\n",
    "            df_entries_temp = df_ANNUAL_rcop[df_ANNUAL_rcop[\"cfy\"].isin(df_rel_cos_temp[\"cfy\"])]\n",
    "            df_cosfy_tagfound = df_entries_temp[(df_entries_temp[\"tag\"] == ls_rel_tags[counter_tag])]\n",
    "\n",
    "            df_cosfy_alltagfound = df_cosfy_alltagfound.append(df_cosfy_tagfound,ignore_index=False)\n",
    "\n",
    "            df_cf_list = df_cosfy_tagfound[[\"cfy\"]]\n",
    "            df_cf_list.drop_duplicates()\n",
    "    #   df_cf_list[\"cik-fy\"] = df_cf_list[\"cik\"] + \"-\" + df_cf_list[\"fy\"]    \n",
    "            df_rel_cos_temp = df_rel_cos_temp[~(df_rel_cos_temp[\"cfy\"].isin(df_cf_list[\"cfy\"]))]\n",
    "\n",
    "            print((ls_rel_tags[counter_tag]+ \" entries \"+np.str(len(df_cosfy_tagfound))))\n",
    "\n",
    "            counter_tag = counter_tag + 1\n",
    "\n",
    "        df_cosfy_alltagfound = pd.merge(df_cosfy_alltagfound,df_currency,left_on=\"uom\",right_on=\"Currency\",how=\"left\")\n",
    "        df_cosfy_alltagfound[\"value Bn USD\"] = df_cosfy_alltagfound[\"value\"] / df_cosfy_alltagfound[\"inUSD\"] / 1000000000\n",
    "\n",
    "        # MERGE THE RELEVANT ENTRIES WITH THE INDUSTRY AND SECTOR\n",
    "        df_ANN_met_found = pd.merge(df_cosfy_alltagfound,df_sic_data,on=\"sic\",how=\"left\")\n",
    "\n",
    "        print(\"Entries Found \"+np.str(len(df_ANN_met_found)))\n",
    "        df_ANN_met_found.to_csv((folder_ann+var_FS+\"/\"+ls_met_tags[counter_met]+\".csv\"))\n",
    "\n",
    "        df_ANN_fnd_cik_fy = df_ANN_met_found[\"cfy\"]\n",
    "        df_ANN_fnd_cik_fy.drop_duplicates(inplace=True)\n",
    "        df_ANN_fnd_cik_fy = pd.DataFrame(df_ANN_fnd_cik_fy)\n",
    "        print(\"CIK-FY Tag Found \"+np.str(len(df_ANN_fnd_cik_fy)))\n",
    "\n",
    "        df_ANN_all_cik_fy = df_ANNUAL[\"cfy\"]\n",
    "        df_ANN_all_cik_fy.drop_duplicates(inplace=True)\n",
    "        df_ANN_all_cik_fy = pd.DataFrame(df_ANN_all_cik_fy)\n",
    "        print(\"CIK-FY All \"+np.str(len(df_ANN_all_cik_fy)))\n",
    "\n",
    "        df_ANN_cik_missing = df_ANN_all_cik_fy[~(df_ANN_all_cik_fy[\"cfy\"].isin(df_ANN_fnd_cik_fy[\"cfy\"]))]\n",
    "        print(\"CIK-FY Missing \"+np.str(len(df_ANN_cik_missing)))\n",
    "\n",
    "    # GET THE IRRELEVANT TAGS\n",
    "        df_irl_tags = df_all_tags[\"tag\"][~(df_all_tags[\"metric\"] == ls_met_tags[counter_met])&(df_all_tags[\"stmt\"] == var_FS)]\n",
    "        df_irl_tags.drop_duplicates(inplace=True)\n",
    "        df_irl_tags = pd.DataFrame(df_irl_tags)\n",
    "\n",
    "    # GET THE GENERIC TAGS\n",
    "        df_gnr_tags = df_all_tags[\"tag_generic\"][(df_all_tags[\"metric\"] == ls_met_tags[counter_met])&((df_all_tags[\"stmt\"] == var_FS))]\n",
    "        df_gnr_tags.drop_duplicates(inplace=True)\n",
    "        df_gnr_tags = pd.DataFrame(df_gnr_tags)\n",
    "        df_gnr_tags.rename(columns={\"tag_generic\":\"tag\"},inplace=True)\n",
    "\n",
    "    # Found Generic Tag\n",
    "        df_ANN_src = df_ANNUAL.copy()\n",
    "\n",
    "        df_found_generic = df_ANN_src[(df_ANN_src[\"stmt\"] == var_FS)\n",
    "                                      &(df_ANN_src[\"qtrs\"] == \"4\")&(df_ANN_src[\"cfy\"].isin(df_ANN_cik_missing[\"cfy\"]))\n",
    "                                      &(df_ANN_src[\"tag\"].str.contains(\"|\".join(df_gnr_tags[\"tag\"])))]\n",
    "\n",
    "        df_found_generic.drop_duplicates(subset=[\"tag\"],inplace=True)\n",
    "        print(\"Found Generic \"+np.str(len(df_found_generic)))\n",
    "        df_found_generic.to_csv((folder_ann+\"/GEN/\"+var_FS+\" \"+ls_met_tags[counter_met]+\" GENERIC FND.csv\"))\n",
    "\n",
    "        counter_met = counter_met + 1\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance Sheet Cash\n",
    "Cash entries are additive and need a special code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET METRICs \n",
    "var_rel_met = \"CASH\"\n",
    "var_FS = var_BS\n",
    "ls_met_tags = pd.unique(df_all_tags[\"metric\"][(df_all_tags[\"stmt\"] == var_FS)&( df_all_tags[\"metric\"]== var_rel_met)])\n",
    "counter_met = 0\n",
    "\n",
    "while counter_met < len(ls_met_tags):\n",
    "\n",
    "# GET RELEVANT TAGS    \n",
    "    df_rel_tags = df_all_tags[(df_all_tags[\"metric\"] == ls_met_tags[counter_met])&((df_all_tags[\"stmt\"] == var_FS))]\n",
    "    df_addln_tags = pd.DataFrame()\n",
    "    df_rel_tags.drop_duplicates(inplace=True)\n",
    "    df_rel_tags = pd.DataFrame(df_rel_tags)\n",
    "    print((\"Tags in Metric \"+ls_met_tags[counter_met]+\" are \"+np.str(len(df_rel_tags))))\n",
    "\n",
    "# PARE DOWN THE FINANCIAL STATEMENT DATA TO ONLY THOSE TAGS THAT ARE RELEVANT\n",
    "    df_ANNUAL_temp = df_ANNUAL.copy()\n",
    "\n",
    "    if var_FS == var_BS:\n",
    "        df_ANNUAL_rel = df_ANNUAL_temp[(df_ANNUAL_temp[\"stmt\"] == var_FS)\n",
    "                                       &(df_ANNUAL_temp[\"tag\"].isin(df_rel_tags[\"tag\"]))]\n",
    "    else:\n",
    "        df_ANNUAL_rel = df_ANNUAL_temp[(df_ANNUAL_temp[\"stmt\"] == var_FS) \n",
    "                                   &(df_ANNUAL_temp[\"tag\"].isin(df_rel_tags[\"tag\"]))\n",
    "                               &(df_ANNUAL_temp[\"qtrs\"] == \"4\")]\n",
    "\n",
    "    print((\"Entries with \"+ls_met_tags[counter_met]+\" relevant tags are \"+np.str(len(df_ANNUAL_rel))))\n",
    "\n",
    "# We are removing the entries from the loop but will add them back in for every iteration.\n",
    "# This helps ensure that multiple entries for CASH will get picked up\n",
    "    li_cash_tags = [\"MARKETABLESECURITIESCURRENT\",\"AVAILABLEFORSALESECURITIESCURRENT\",\"SHORTTERMINVESTMENTS\"]\n",
    "    df_rel_tags = df_rel_tags[~(df_rel_tags[\"tag\"].isin(li_cash_tags))]\n",
    "\n",
    "    ls_rel_tags = pd.unique(df_rel_tags[\"tag\"])\n",
    "\n",
    "    df_ANNUAL_temp = df_ANNUAL_rel.copy()\n",
    "    df_rel_cos = df_ANNUAL_temp[[\"cfy\"]]\n",
    "    df_rel_cos.drop_duplicates(subset=[\"cfy\"],inplace=True)\n",
    "    df_ANNUAL_temp = pd.DataFrame()\n",
    "    df_rel_cos_temp = df_rel_cos.copy()\n",
    "    print((\"Number of Relevant Co-FY Combos \"+np.str(len(df_rel_cos_temp))))\n",
    "\n",
    "    # Create a copy of the relevant entries\n",
    "    df_ANNUAL_rcop = df_ANNUAL_rel.copy()\n",
    "\n",
    "    df_entries_temp = pd.DataFrame()\n",
    "    df_cosfy_tagfound = pd.DataFrame()\n",
    "    df_cosfy_alltagfound = pd.DataFrame()\n",
    "    df_cf_list = pd.DataFrame()\n",
    "    counter_tag = 0\n",
    "\n",
    "    while counter_tag < len(ls_rel_tags):\n",
    "\n",
    "# Adding back tge deleted cash entries        \n",
    "        ls_rel_tags2 = np.append(ls_rel_tags[counter_tag],li_cash_tags)\n",
    "\n",
    "        print(ls_rel_tags2)\n",
    "\n",
    "        df_entries_temp = df_ANNUAL_rcop[df_ANNUAL_rcop[\"cfy\"].isin(df_rel_cos_temp[\"cfy\"])]\n",
    "        df_cosfy_tagfound = df_entries_temp[(df_entries_temp[\"tag\"].isin(ls_rel_tags2))]\n",
    "\n",
    "        df_cosfy_alltagfound = df_cosfy_alltagfound.append(df_cosfy_tagfound,ignore_index=False)\n",
    "\n",
    "        df_cf_list = df_cosfy_tagfound[[\"cfy\"]]\n",
    "        df_cf_list.drop_duplicates()\n",
    "#   df_cf_list[\"cik-fy\"] = df_cf_list[\"cik\"] + \"-\" + df_cf_list[\"fy\"]    \n",
    "        df_rel_cos_temp = df_rel_cos_temp[~(df_rel_cos_temp[\"cfy\"].isin(df_cf_list[\"cfy\"]))]\n",
    "\n",
    "        print((ls_rel_tags[counter_tag]+ \" entries \"+np.str(len(df_cosfy_tagfound))))\n",
    "\n",
    "        counter_tag = counter_tag + 1\n",
    "\n",
    "    df_cosfy_alltagfound = pd.merge(df_cosfy_alltagfound,df_currency,left_on=\"uom\",right_on=\"Currency\",how=\"left\")\n",
    "    df_cosfy_alltagfound[\"value Bn USD\"] = df_cosfy_alltagfound[\"value\"] / df_cosfy_alltagfound[\"inUSD\"] / 1000000000\n",
    "\n",
    "    # MERGE THE RELEVANT ENTRIES WITH THE INDUSTRY AND SECTOR\n",
    "    df_ANN_met_found = pd.merge(df_cosfy_alltagfound,df_sic_data,on=\"sic\",how=\"left\")\n",
    "\n",
    "    print(\"Entries Found \"+np.str(len(df_ANN_met_found)))\n",
    "    df_ANN_met_found.to_csv((folder_ann+var_FS+\"/\"+ls_met_tags[counter_met]+\".csv\"))\n",
    "\n",
    "    df_ANN_fnd_cik_fy = df_ANN_met_found[\"cfy\"]\n",
    "    df_ANN_fnd_cik_fy.drop_duplicates(inplace=True)\n",
    "    df_ANN_fnd_cik_fy = pd.DataFrame(df_ANN_fnd_cik_fy)\n",
    "    print(\"CIK-FY Tag Found \"+np.str(len(df_ANN_fnd_cik_fy)))\n",
    "\n",
    "    df_ANN_all_cik_fy = df_ANNUAL[\"cfy\"]\n",
    "    df_ANN_all_cik_fy.drop_duplicates(inplace=True)\n",
    "    df_ANN_all_cik_fy = pd.DataFrame(df_ANN_all_cik_fy)\n",
    "    print(\"CIK-FY All \"+np.str(len(df_ANN_all_cik_fy)))\n",
    "\n",
    "    df_ANN_cik_missing = df_ANN_all_cik_fy[~(df_ANN_all_cik_fy[\"cfy\"].isin(df_ANN_fnd_cik_fy[\"cfy\"]))]\n",
    "    print(\"CIK-FY Missing \"+np.str(len(df_ANN_cik_missing)))\n",
    "\n",
    "# GET THE IRRELEVANT TAGS\n",
    "    df_irl_tags = df_all_tags[\"tag\"][~(df_all_tags[\"metric\"] == ls_met_tags[counter_met])&(df_all_tags[\"stmt\"] == var_FS)]\n",
    "    df_irl_tags.drop_duplicates(inplace=True)\n",
    "    df_irl_tags = pd.DataFrame(df_irl_tags)\n",
    "\n",
    "# GET THE GENERIC TAGS\n",
    "    df_gnr_tags = df_all_tags[\"tag_generic\"][(df_all_tags[\"metric\"] == ls_met_tags[counter_met])&((df_all_tags[\"stmt\"] == var_FS))]\n",
    "    df_gnr_tags.drop_duplicates(inplace=True)\n",
    "    df_gnr_tags = pd.DataFrame(df_gnr_tags)\n",
    "    df_gnr_tags.rename(columns={\"tag_generic\":\"tag\"},inplace=True)\n",
    "\n",
    "# Found Generic Tag\n",
    "    df_ANN_src = df_ANNUAL.copy()\n",
    "\n",
    "    df_found_generic = df_ANN_src[(df_ANN_src[\"stmt\"] == var_FS)\n",
    "                                  &(df_ANN_src[\"qtrs\"] == \"4\")&(df_ANN_src[\"cfy\"].isin(df_ANN_cik_missing[\"cfy\"]))\n",
    "                                  &(df_ANN_src[\"tag\"].str.contains(\"|\".join(df_gnr_tags[\"tag\"])))]\n",
    "\n",
    "    df_found_generic.drop_duplicates(subset=[\"tag\"],inplace=True)\n",
    "    print(\"Found Generic \"+np.str(len(df_found_generic)))\n",
    "    df_found_generic.to_csv((folder_ann+\"/GEN/\"+var_FS+\" \"+ls_met_tags[counter_met]+\" GENERIC FND.csv\"))\n",
    "\n",
    "    counter_met = counter_met + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nc_tags.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASH FLOW NET CASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_FS = var_CF\n",
    "var_rel_met = \"NETCASH\"\n",
    "df_cosfy_alltagfound = pd.DataFrame()\n",
    "\n",
    "df_ANNUAL_temp = df_ANNUAL.copy()\n",
    "ls_opr = [\"NETCASHPROVIDEDBYUSEDINOPERATINGACTIVITIES\",\"NETCASHPROVIDEDBYUSEDINOPERATINGACTIVITIESCONTINUINGOPERATIONS\"]\n",
    "df_cosfy_tagfound = df_ANNUAL_temp[(df_ANNUAL_temp[\"tag\"].isin(ls_opr))]\n",
    "df_cosfy_tagfound.sort_values(by=[\"cfy\",\"value\"],inplace=True)\n",
    "df_cosfy_tagfound.drop_duplicates(subset=\"cfy\",inplace=True)\n",
    "df_cosfy_alltagfound = df_cosfy_alltagfound.append(df_cosfy_tagfound,ignore_index=False)\n",
    "print((var_rel_met+ \" OPRT entries \"+np.str(len(df_cosfy_tagfound))))\n",
    "\n",
    "\n",
    "df_ANNUAL_temp = df_ANNUAL.copy()\n",
    "ls_inv = [\"NETCASHPROVIDEDBYUSEDININVESTINGACTIVITIES\",\"NETCASHPROVIDEDBYUSEDININVESTINGACTIVITIESCONTINUINGOPERATIONS\"]\n",
    "df_cosfy_tagfound = df_ANNUAL_temp[(df_ANNUAL_temp[\"tag\"].isin(ls_inv))]\n",
    "df_cosfy_tagfound.sort_values(by=[\"cfy\",\"value\"],inplace=True)\n",
    "df_cosfy_tagfound.drop_duplicates(subset=\"cfy\",inplace=True)\n",
    "df_cosfy_alltagfound = df_cosfy_alltagfound.append(df_cosfy_tagfound,ignore_index=False)\n",
    "print((var_rel_met+ \" INVST entries \"+np.str(len(df_cosfy_tagfound))))\n",
    "\n",
    "df_ANNUAL_temp = df_ANNUAL.copy()\n",
    "ls_fin = [\"NETCASHPROVIDEDBYUSEDINFINANCINGACTIVITIES\",\"NETCASHPROVIDEDBYUSEDINFINANCINGACTIVITIESCONTINUINGOPERATIONS\"]\n",
    "df_cosfy_tagfound = df_ANNUAL_temp[(df_ANNUAL_temp[\"tag\"].isin(ls_fin))]\n",
    "df_cosfy_tagfound.sort_values(by=[\"cfy\",\"value\"],inplace=True)\n",
    "df_cosfy_tagfound.drop_duplicates(subset=\"cfy\",inplace=True)\n",
    "df_cosfy_alltagfound = df_cosfy_alltagfound.append(df_cosfy_tagfound,ignore_index=False)\n",
    "print((var_rel_met+ \" FINANC entries \"+np.str(len(df_cosfy_tagfound))))\n",
    "\n",
    "df_cosfy_alltagfound = pd.merge(df_cosfy_alltagfound,df_currency,left_on=\"uom\",right_on=\"Currency\",how=\"left\")\n",
    "df_cosfy_alltagfound[\"value Bn USD\"] = df_cosfy_alltagfound[\"value\"] / df_cosfy_alltagfound[\"inUSD\"] / 1000000000\n",
    "\n",
    "# MERGE THE RELEVANT ENTRIES WITH THE INDUSTRY AND SECTOR\n",
    "df_ANN_met_found = pd.merge(df_cosfy_alltagfound,df_sic_data,on=\"sic\",how=\"left\")\n",
    "    \n",
    "print(\"Entries Found \"+np.str(len(df_ANN_met_found)))\n",
    "df_ANN_met_found.to_csv((folder_ann+var_FS+\"/\"+var_rel_met+\".csv\"))\n",
    "\n",
    "df_ANN_fnd_cik_fy = df_ANN_met_found[\"cfy\"]\n",
    "df_ANN_fnd_cik_fy.drop_duplicates(inplace=True)\n",
    "df_ANN_fnd_cik_fy = pd.DataFrame(df_ANN_fnd_cik_fy)\n",
    "print(\"CIK-FY Tag Found \"+np.str(len(df_ANN_fnd_cik_fy)))\n",
    "\n",
    "df_ANN_all_cik_fy = df_ANNUAL[\"cfy\"]\n",
    "df_ANN_all_cik_fy.drop_duplicates(inplace=True)\n",
    "df_ANN_all_cik_fy = pd.DataFrame(df_ANN_all_cik_fy)\n",
    "print(\"CIK-FY All \"+np.str(len(df_ANN_all_cik_fy)))\n",
    "\n",
    "df_ANN_cik_missing = df_ANN_all_cik_fy[~(df_ANN_all_cik_fy[\"cfy\"].isin(df_ANN_fnd_cik_fy[\"cfy\"]))]\n",
    "print(\"CIK-FY Missing \"+np.str(len(df_ANN_cik_missing)))\n",
    "    \n",
    "# GET THE IRRELEVANT TAGS\n",
    "df_irl_tags = df_all_tags[\"tag\"][~(df_all_tags[\"metric\"] == var_rel_met)&(df_all_tags[\"stmt\"] == var_FS)]\n",
    "df_irl_tags.drop_duplicates(inplace=True)\n",
    "df_irl_tags = pd.DataFrame(df_irl_tags)\n",
    "\n",
    "# GET THE GENERIC TAGS\n",
    "df_gnr_tags = df_all_tags[\"tag_generic\"][(df_all_tags[\"metric\"] == var_rel_met)&((df_all_tags[\"stmt\"] == var_FS))]\n",
    "df_gnr_tags.drop_duplicates(inplace=True)\n",
    "df_gnr_tags = pd.DataFrame(df_gnr_tags)\n",
    "df_gnr_tags.rename(columns={\"tag_generic\":\"tag\"},inplace=True)\n",
    "\n",
    "# Found Generic Tag\n",
    "df_all_10K_src = df_ANNUAL.copy()\n",
    "df_found_generic = df_all_10K_src[(df_all_10K_src[\"stmt\"] == var_FS)\n",
    "                                  &(df_all_10K_src[\"qtrs\"] == \"4\")&(df_all_10K_src[\"cfy\"].isin(df_ANN_cik_missing[\"cfy\"]))\n",
    "                                  &(df_all_10K_src[\"tag\"].str.contains(\"|\".join(df_gnr_tags[\"tag\"])))]\n",
    "df_found_generic.drop_duplicates(subset=[\"tag\"],inplace=True)\n",
    "print(\"Found Generic \"+np.str(len(df_found_generic)))\n",
    "df_found_generic.to_csv((folder_ann+\"/GEN/\"+var_FS+\" \"+var_rel_met+\" GENERIC FND.csv\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

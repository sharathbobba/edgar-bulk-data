{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "var_BS = \"BS\"\n",
    "var_CF = \"CF\"\n",
    "var_IS = \"IS\"\n",
    "\n",
    "folder_combined = <>\n",
    "folder_pas = <>\n",
    "folder_cos = <>\n",
    "folder_mai = <>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_10K = pd.DataFrame()\n",
    "# Get all Entries\n",
    "df_col_types = {\"sic\":str,\"cik\":str,\"fy\":str,\"qtrs\":str}\n",
    "df_all_10K = pd.read_csv((folder_pas+\"10-K_AllEntries.csv.zip\"),dtype=df_col_types)\n",
    "df_all_10K.drop([\"Unnamed: 0\"],axis=1,inplace=True)\n",
    "df_all_10K[\"tag\"] = df_all_10K[\"tag\"].str.upper()\n",
    "print(len(df_all_10K))\n",
    "\n",
    "df_col_types = {\"sic\":str,\"cik\":str,\"fy\":str,\"qtrs\":str}\n",
    "df_all_20F = pd.read_csv((folder_pas+\"20-F_AllEntries.csv.zip\"),dtype=df_col_types)\n",
    "df_all_20F.drop([\"Unnamed: 0\"],axis=1,inplace=True)\n",
    "df_all_20F[\"tag\"] = df_all_20F[\"tag\"].str.upper()\n",
    "print(len(df_all_20F))\n",
    "\n",
    "df_col_types = {\"sic\":str,\"cik\":str,\"fy\":str,\"qtrs\":str}\n",
    "df_all_40F = pd.read_csv((folder_pas+\"40-F_AllEntries.csv.zip\"),dtype=df_col_types)\n",
    "df_all_40F.drop([\"Unnamed: 0\"],axis=1,inplace=True)\n",
    "df_all_40F[\"tag\"] = df_all_40F[\"tag\"].str.upper()\n",
    "print(len(df_all_40F))\n",
    "\n",
    "df_ANNUAL = df_all_10K.copy()\n",
    "print(len(df_ANNUAL))\n",
    "df_ANNUAL = df_ANNUAL.append(df_all_20F,ignore_index=True)\n",
    "print(len(df_ANNUAL))\n",
    "df_ANNUAL = df_ANNUAL.append(df_all_40F,ignore_index=True)\n",
    "print(len(df_ANNUAL))\n",
    "\n",
    "df_ANNUAL_temp = pd.DataFrame()\n",
    "df_all_10K = pd.DataFrame()\n",
    "df_all_20F = pd.DataFrame()\n",
    "df_all_40F = pd.DataFrame()\n",
    "\n",
    "df_ANNUAL[\"date_period\"] = pd.to_datetime(df_ANNUAL[\"date_period\"])\n",
    "df_ANNUAL = df_ANNUAL[(~(df_ANNUAL[\"fy\"].isnull()))]\n",
    "df_ANNUAL[\"calyr\"] = df_ANNUAL[\"date_period\"].dt.year\n",
    "df_ANNUAL[\"ffy\"] = np.where(df_ANNUAL[\"fy\"].astype(int) <= df_ANNUAL[\"calyr\"],df_ANNUAL[\"calyr\"],df_ANNUAL[\"fy\"])\n",
    "df_ANNUAL[\"cfy\"] = df_ANNUAL[\"cik\"] + \"-\" + df_ANNUAL[\"ffy\"].astype(str)\n",
    "\n",
    "df_currency = pd.read_excel((folder_mai+\"Currency Data.xlsx\"),sheet_name=\"subset\")\n",
    "\n",
    "# GET ALL TAGS\n",
    "df_all_tags = pd.read_excel((folder_mai+\"Tags and Stats.xlsx\"),sheet_name=\"Tag List\")\n",
    "df_all_tags.sort_values(by=[\"stmt\",\"metric\",\"tag_order\"],ascending=True,inplace=True)\n",
    "print(len(df_all_tags))\n",
    "\n",
    "# GET THE INDUSTRY AND THE SECTOR\n",
    "df_col_types = {\"sic\":str,\"cik\":str,\"fy\":str,\"qtrs\":str}\n",
    "df_cik_sic_align = pd.read_csv((folder_mai+\"cik_sic_align.csv\"),dtype=df_col_types)\n",
    "df_sic_data = df_cik_sic_align[[\"sic\",\"Office\",\"Industry Title\"]] \n",
    "df_sic_data.drop_duplicates(subset=\"sic\",inplace=True)\n",
    "\n",
    "df_ANNUAL.to_csv((folder_pas+\" ALL ANNUAL ENTRIES.csv\"))\n",
    "print(len(df_ANNUAL))\n",
    "df_ANNUAL = df_ANNUAL[[\"cik\",\"name\",\"sic\",\"countryba\",\"stmt\",\"tag\",\"negating\",\"date_period\",\"qtrs\",\"uom\",\"value\",\"ffy\",\"cfy\"]][df_ANNUAL[\"coreg\"].isnull()]\n",
    "print(len(df_ANNUAL))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_types = {\"sic\":str,\"cik\":str,\"fy\":str,\"qtrs\":str,\"calyr\":str,\"ffy\":str}\n",
    "df_ANNUAL = pd.read_csv((folder_pas+\" ALL ANNUAL ENTRIES.csv.zip\"),dtype=df_col_types)\n",
    "print(len(df_ANNUAL))\n",
    "df_ANNUAL = df_ANNUAL[[\"cik\",\"name\",\"sic\",\"countryba\",\"stmt\",\"tag\",\"negating\",\"date_period\",\"qtrs\",\"uom\",\"value\",\"ffy\",\"cfy\"]][df_ANNUAL[\"coreg\"].isnull()]\n",
    "print(len(df_ANNUAL))\n",
    "\n",
    "# GET ALL TAGS\n",
    "df_all_tags = pd.read_excel((folder_mai+\"Tags and Stats.xlsx\"),sheet_name=\"Tag List\")\n",
    "df_all_tags.sort_values(by=[\"stmt\",\"metric\",\"tag_order\"],ascending=True,inplace=True)\n",
    "print(len(df_all_tags))\n",
    "\n",
    "# GET THE INDUSTRY AND THE SECTOR\n",
    "df_col_types = {\"sic\":str,\"cik\":str,\"fy\":str,\"qtrs\":str}\n",
    "df_cik_sic_align = pd.read_csv((folder_mai+\"cik_sic_align.csv\"),dtype=df_col_types)\n",
    "df_sic_data = df_cik_sic_align[[\"sic\",\"Office\",\"Industry Title\"]] \n",
    "df_sic_data.drop_duplicates(subset=\"sic\",inplace=True)\n",
    "\n",
    "df_currency = pd.read_excel((folder_mai+\"Currency Data.xlsx\"),sheet_name=\"subset\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data of a Single Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_co_name = \"SALES\"\n",
    "df_ANNUAL_temp = df_ANNUAL.copy()\n",
    "df_co_data = df_ANNUAL_temp[df_ANNUAL_temp[\"name\"].str.contains(var_co_name)]\n",
    "df_ANNUAL_temp = pd.DataFrame()\n",
    "df_co_data.drop_duplicates(subset=[\"name\"],inplace=True)\n",
    "df_co_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data of the Foreign company \n",
    "var_co_name = \"SFDC\"\n",
    "var_cik = \"1108524\"\n",
    "df_ANNUAL_temp = df_ANNUAL.copy()\n",
    "df_co = df_ANNUAL_temp[df_ANNUAL_temp[\"cik\"].str.contains(var_cik)]\n",
    "df_ANNUAL_temp = pd.DataFrame()\n",
    "print(len(df_co))\n",
    "df_co.to_csv((folder_cos+var_co_name+\" \"+var_cik+\" ANNUAL.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Income Statement Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_FS = var_IS\n",
    "\n",
    "# GET METRICs \n",
    "df_met_tags = df_all_tags[\"metric\"][(df_all_tags[\"stmt\"] == var_FS)]\n",
    "df_met_tags.drop_duplicates(inplace=True)\n",
    "df_met_tags = pd.DataFrame(df_met_tags)\n",
    "\n",
    "df_met_tags2 = df_met_tags.reset_index(level=0,drop=False)\n",
    "df_met_tags2.drop(\"index\",axis=1,inplace=True)\n",
    "df_met_tags4 = df_met_tags2[\"metric\"]\n",
    "\n",
    "df_all_tags_copy = df_all_tags.copy()\n",
    "counter_met = 0\n",
    "\n",
    "while counter_met < len(df_met_tags4):\n",
    "    \n",
    "# GET RELEVANT TAGS    \n",
    "    df_rel_tags = df_all_tags_copy[(df_all_tags_copy[\"metric\"] == df_met_tags4[counter_met])&((df_all_tags_copy[\"stmt\"] == var_FS))]\n",
    "    df_rel_tags.drop_duplicates(inplace=True)\n",
    "    df_rel_tags = pd.DataFrame(df_rel_tags)\n",
    "    print((\"Tags in Metric \"+df_met_tags4[counter_met]+\" are \"+np.str(len(df_rel_tags))))\n",
    "\n",
    "# PARE DOWN THE FINANCIAL STATEMENT DATA TO ONLY THOSE TAGS THAT ARE RELEVANT\n",
    "\n",
    "    df_ANNUAL_temp = df_ANNUAL.copy()\n",
    "    df_ANNUAL_rel = df_ANNUAL_temp[(df_ANNUAL_temp[\"stmt\"] == var_FS) \n",
    "                                   &(df_ANNUAL_temp[\"tag\"].isin(df_rel_tags[\"tag\"]))\n",
    "                               &(df_ANNUAL_temp[\"qtrs\"] == \"4\")]\n",
    "\n",
    "    print((\"Entries with \"+df_met_tags4[counter_met]+\" relevant tags are \"+np.str(len(df_ANNUAL_rel))))\n",
    "    \n",
    "    # RESET THE INDEX ON THE TAG DATAFRAME (# see INDEX_WOES notes)\n",
    "    df_rel_tags2 = df_rel_tags.reset_index(level=0,drop=False)\n",
    "    df_rel_tags2.drop(\"index\",axis=1,inplace=True)\n",
    "    df_rel_tags4 = df_rel_tags2[\"tag\"]\n",
    "    \n",
    "    df_ANNUAL_temp = df_ANNUAL_rel.copy()\n",
    "    df_rel_cos = df_ANNUAL_temp[[\"cfy\"]]\n",
    "    df_rel_cos.drop_duplicates(subset=[\"cfy\"],inplace=True)\n",
    "    df_ANNUAL_temp = pd.DataFrame()\n",
    "    df_rel_cos_temp = df_rel_cos.copy()\n",
    "    print((\"Number of Relevant Co-FY Combos \"+np.str(len(df_rel_cos_temp))))\n",
    "    \n",
    "    # Create a copy of the relevant entries\n",
    "    df_ANNUAL_rcop = df_ANNUAL_rel.copy()\n",
    "\n",
    "    df_entries_temp = pd.DataFrame()\n",
    "    df_cosfy_tagfound = pd.DataFrame()\n",
    "    df_cosfy_alltagfound = pd.DataFrame()\n",
    "    df_cf_list = pd.DataFrame()\n",
    "    counter_tag = 0\n",
    "    \n",
    "    while counter_tag < len(df_rel_tags4):\n",
    "    \n",
    "        df_entries_temp = df_ANNUAL_rcop[df_ANNUAL_rcop[\"cfy\"].isin(df_rel_cos_temp[\"cfy\"])]\n",
    "        df_cosfy_tagfound = df_entries_temp[(df_entries_temp[\"tag\"] == df_rel_tags4[counter_tag])]\n",
    "    \n",
    "        df_cosfy_alltagfound = df_cosfy_alltagfound.append(df_cosfy_tagfound,ignore_index=False)\n",
    "    \n",
    "        df_cf_list = df_cosfy_tagfound[[\"cfy\"]]\n",
    "        df_cf_list.drop_duplicates()\n",
    "#   df_cf_list[\"cik-fy\"] = df_cf_list[\"cik\"] + \"-\" + df_cf_list[\"fy\"]    \n",
    "        df_rel_cos_temp = df_rel_cos_temp[~(df_rel_cos_temp[\"cfy\"].isin(df_cf_list[\"cfy\"]))]\n",
    "    \n",
    "        print((df_rel_tags4[counter_tag]+ \" entries \"+np.str(len(df_cosfy_tagfound))))\n",
    "    \n",
    "        counter_tag = counter_tag + 1\n",
    "\n",
    "    df_cosfy_alltagfound = pd.merge(df_cosfy_alltagfound,df_currency,left_on=\"uom\",right_on=\"Currency\",how=\"left\")\n",
    "    df_cosfy_alltagfound[\"value Bn USD\"] = df_cosfy_alltagfound[\"value\"] / df_cosfy_alltagfound[\"inUSD\"] / 1000000000\n",
    "\n",
    "    # MERGE THE RELEVANT ENTRIES WITH THE INDUSTRY AND SECTOR\n",
    "    df_10K_met_found = pd.merge(df_cosfy_alltagfound,df_sic_data,on=\"sic\",how=\"left\")\n",
    "    \n",
    "    print(\"Entries Found \"+np.str(len(df_10K_met_found)))\n",
    "    df_10K_met_found.to_csv((folder_cos+\"ANNUAL \"+var_FS+\" \"+df_met_tags4[counter_met]+\" 1 FOUND.csv\"))\n",
    "\n",
    "    df_10K_fnd_cik_fy = df_10K_met_found[\"cfy\"]\n",
    "    df_10K_fnd_cik_fy.drop_duplicates(inplace=True)\n",
    "    df_10K_fnd_cik_fy = pd.DataFrame(df_10K_fnd_cik_fy)\n",
    "    print(\"CIK-FY Tag Found \"+np.str(len(df_10K_fnd_cik_fy)))\n",
    "\n",
    "    df_10K_all_cik_fy = df_ANNUAL[\"cfy\"]\n",
    "    df_10K_all_cik_fy.drop_duplicates(inplace=True)\n",
    "    df_10K_all_cik_fy = pd.DataFrame(df_10K_all_cik_fy)\n",
    "    print(\"CIK-FY All \"+np.str(len(df_10K_all_cik_fy)))\n",
    "\n",
    "    df_10K_cik_missing = df_10K_all_cik_fy[~(df_10K_all_cik_fy[\"cfy\"].isin(df_10K_fnd_cik_fy[\"cfy\"]))]\n",
    "    print(\"CIK-FY Missing \"+np.str(len(df_10K_cik_missing)))\n",
    "    \n",
    "    # GET THE IRRELEVANT TAGS\n",
    "    df_irl_tags = df_all_tags[\"tag\"][~(df_all_tags[\"metric\"] == df_met_tags4[counter_met])&(df_all_tags[\"stmt\"] == var_FS)]\n",
    "    df_irl_tags.drop_duplicates(inplace=True)\n",
    "    df_irl_tags = pd.DataFrame(df_irl_tags)\n",
    "\n",
    "# GET THE GENERIC TAGS\n",
    "    df_gnr_tags = df_all_tags[\"tag_generic\"][(df_all_tags[\"metric\"] == df_met_tags4[counter_met])&((df_all_tags[\"stmt\"] == var_FS))]\n",
    "    df_gnr_tags.drop_duplicates(inplace=True)\n",
    "    df_gnr_tags = pd.DataFrame(df_gnr_tags)\n",
    "    df_gnr_tags.rename(columns={\"tag_generic\":\"tag\"},inplace=True)\n",
    "\n",
    "# Found Generic Tag\n",
    "    df_all_10K_src = df_ANNUAL.copy()\n",
    "#df_found_generic = df_all_10K[(df_10K_copy[\"stmt\"] == var_IS)&(df_10K_copy[\"form\"] == \"10-K\")&(df_10K_copy[\"qtrs\"] == \"4\")&(df_all_10K[\"cik-fy\"].isin(df_10K_cik_missing[\"cik-fy\"]))&(df_all_10K[\"tag\"].str.contains(\"|\".join(df_gnr_tags[\"tag\"])))]\n",
    "    df_found_generic = df_all_10K_src[(df_all_10K_src[\"stmt\"] == var_FS)\n",
    "                                  &(df_all_10K_src[\"qtrs\"] == \"4\")&(df_all_10K_src[\"cfy\"].isin(df_10K_cik_missing[\"cfy\"]))\n",
    "                                  &(df_all_10K_src[\"tag\"].str.contains(\"|\".join(df_gnr_tags[\"tag\"])))]\n",
    "#df_found_generic.to_csv((folder_cos+\"10K\"+var_rel_met+\" 2 GENERIC FND.csv\"))\n",
    "#df_10K_fnd_gnr = df_found_generic[\"cik-fy\"]\n",
    "#df_10K_fnd_gnr.drop_duplicates(inplace=True)\n",
    "    df_found_generic.drop_duplicates(subset=[\"tag\"],inplace=True)\n",
    "    print(\"Found Generic \"+np.str(len(df_found_generic)))\n",
    "    df_found_generic.to_csv((folder_cos+\"ANNUAL \"+var_FS+\" \"+df_met_tags4[counter_met]+\" 2 GENERIC FND.csv\"))\n",
    "    \n",
    "    counter_met = counter_met + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_irl_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rel_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance Sheet Entries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_FS = var_BS\n",
    "\n",
    "# GET METRICs \n",
    "df_met_tags = df_all_tags[\"metric\"][(df_all_tags[\"stmt\"] == var_FS)]\n",
    "df_met_tags.drop_duplicates(inplace=True)\n",
    "df_met_tags = pd.DataFrame(df_met_tags)\n",
    "\n",
    "df_met_tags2 = df_met_tags.reset_index(level=0,drop=False)\n",
    "df_met_tags2.drop(\"index\",axis=1,inplace=True)\n",
    "df_met_tags4 = df_met_tags2[\"metric\"]\n",
    "\n",
    "df_all_tags_copy = df_all_tags.copy()\n",
    "counter_met = 0\n",
    "\n",
    "while counter_met < len(df_met_tags4):\n",
    "    \n",
    "# GET RELEVANT TAGS    \n",
    "    df_rel_tags = df_all_tags_copy[(df_all_tags_copy[\"metric\"] == df_met_tags4[counter_met])&((df_all_tags_copy[\"stmt\"] == var_FS))]\n",
    "    df_rel_tags.drop_duplicates(inplace=True)\n",
    "    df_rel_tags = pd.DataFrame(df_rel_tags)\n",
    "    print((\"Tags in Metric \"+df_met_tags4[counter_met]+\" are \"+np.str(len(df_rel_tags))))\n",
    "\n",
    "# PARE DOWN THE FINANCIAL STATEMENT DATA TO ONLY THOSE TAGS THAT ARE RELEVANT\n",
    "    df_ANNUAL_temp = df_ANNUAL.copy()\n",
    "    df_ANNUAL_rel = df_ANNUAL_temp[(df_ANNUAL_temp[\"stmt\"] == var_FS) &(df_ANNUAL_temp[\"tag\"].isin(df_rel_tags[\"tag\"]))\n",
    "                               ]\n",
    "\n",
    "    print((\"Entries with \"+df_met_tags4[counter_met]+\" relevant tags are \"+np.str(len(df_ANNUAL_rel))))\n",
    "    \n",
    "    # RESET THE INDEX ON THE TAG DATAFRAME (# see INDEX_WOES notes)\n",
    "    df_rel_tags2 = df_rel_tags.reset_index(level=0,drop=False)\n",
    "    df_rel_tags2.drop(\"index\",axis=1,inplace=True)\n",
    "    df_rel_tags4 = df_rel_tags2[\"tag\"]\n",
    "    \n",
    "    df_ANNUAL_temp = df_ANNUAL_rel.copy()\n",
    "    df_rel_cos = df_ANNUAL_temp[[\"cfy\"]]\n",
    "    df_rel_cos.drop_duplicates(subset=[\"cfy\"],inplace=True)\n",
    "    df_ANNUAL_temp = pd.DataFrame()\n",
    "    df_rel_cos_temp = df_rel_cos.copy()\n",
    "    print((\"Number of Relevant Co-FY Combos \"+np.str(len(df_rel_cos_temp))))\n",
    "    \n",
    "    # Create a copy of the relevant entries\n",
    "    df_ANNUAL_rcop = df_ANNUAL_rel.copy()\n",
    "\n",
    "    df_entries_temp = pd.DataFrame()\n",
    "    df_cosfy_tagfound = pd.DataFrame()\n",
    "    df_cosfy_alltagfound = pd.DataFrame()\n",
    "    df_cf_list = pd.DataFrame()\n",
    "    counter_tag = 0\n",
    "    \n",
    "    while counter_tag < len(df_rel_tags4):\n",
    "    \n",
    "        df_entries_temp = df_ANNUAL_rcop[df_ANNUAL_rcop[\"cfy\"].isin(df_rel_cos_temp[\"cfy\"])]\n",
    "        df_cosfy_tagfound = df_entries_temp[(df_entries_temp[\"tag\"] == df_rel_tags4[counter_tag])]\n",
    "    \n",
    "        df_cosfy_alltagfound = df_cosfy_alltagfound.append(df_cosfy_tagfound,ignore_index=False)\n",
    "    \n",
    "        df_cf_list = df_cosfy_tagfound[[\"cfy\"]]\n",
    "        df_cf_list.drop_duplicates()\n",
    "#   df_cf_list[\"cik-fy\"] = df_cf_list[\"cik\"] + \"-\" + df_cf_list[\"fy\"]    \n",
    "        df_rel_cos_temp = df_rel_cos_temp[~(df_rel_cos_temp[\"cfy\"].isin(df_cf_list[\"cfy\"]))]\n",
    "    \n",
    "        print((df_rel_tags4[counter_tag]+ \" entries \"+np.str(len(df_cosfy_tagfound))))\n",
    "    \n",
    "        counter_tag = counter_tag + 1\n",
    "\n",
    "    df_cosfy_alltagfound = pd.merge(df_cosfy_alltagfound,df_currency,left_on=\"uom\",right_on=\"Currency\",how=\"left\")\n",
    "    df_cosfy_alltagfound[\"value Bn USD\"] = df_cosfy_alltagfound[\"value\"] / df_cosfy_alltagfound[\"inUSD\"] / 1000000000\n",
    "\n",
    "    # MERGE THE RELEVANT ENTRIES WITH THE INDUSTRY AND SECTOR\n",
    "    df_10K_met_found = pd.merge(df_cosfy_alltagfound,df_sic_data,on=\"sic\",how=\"left\")\n",
    "    \n",
    "    print(\"Entries Found \"+np.str(len(df_10K_met_found)))\n",
    "    df_10K_met_found.to_csv((folder_cos+\"ANNUAL \"+var_FS+\" \"+df_met_tags4[counter_met]+\" 1 FOUND.csv\"))\n",
    "\n",
    "    df_10K_fnd_cik_fy = df_10K_met_found[\"cfy\"]\n",
    "    df_10K_fnd_cik_fy.drop_duplicates(inplace=True)\n",
    "    df_10K_fnd_cik_fy = pd.DataFrame(df_10K_fnd_cik_fy)\n",
    "    print(\"CIK-FY Tag Found \"+np.str(len(df_10K_fnd_cik_fy)))\n",
    "\n",
    "    df_10K_all_cik_fy = df_ANNUAL[\"cfy\"]\n",
    "    df_10K_all_cik_fy.drop_duplicates(inplace=True)\n",
    "    df_10K_all_cik_fy = pd.DataFrame(df_10K_all_cik_fy)\n",
    "    print(\"CIK-FY All \"+np.str(len(df_10K_all_cik_fy)))\n",
    "\n",
    "    df_10K_cik_missing = df_10K_all_cik_fy[~(df_10K_all_cik_fy[\"cfy\"].isin(df_10K_fnd_cik_fy[\"cfy\"]))]\n",
    "    print(\"CIK-FY Missing \"+np.str(len(df_10K_cik_missing)))\n",
    "    \n",
    "    # GET THE IRRELEVANT TAGS\n",
    "    df_irl_tags = df_all_tags[\"tag\"][~(df_all_tags[\"metric\"] == df_met_tags4[counter_met])&(df_all_tags[\"stmt\"] == var_FS)]\n",
    "    df_irl_tags.drop_duplicates(inplace=True)\n",
    "    df_irl_tags = pd.DataFrame(df_irl_tags)\n",
    "\n",
    "# GET THE GENERIC TAGS\n",
    "    df_gnr_tags = df_all_tags[\"tag_generic\"][(df_all_tags[\"metric\"] == df_met_tags4[counter_met])&((df_all_tags[\"stmt\"] == var_FS))]\n",
    "    df_gnr_tags.drop_duplicates(inplace=True)\n",
    "    df_gnr_tags = pd.DataFrame(df_gnr_tags)\n",
    "    df_gnr_tags.rename(columns={\"tag_generic\":\"tag\"},inplace=True)\n",
    "\n",
    "# Found Generic Tag\n",
    "    df_all_10K_src = df_ANNUAL.copy()\n",
    "#df_found_generic = df_all_10K[(df_10K_copy[\"stmt\"] == var_IS)&(df_10K_copy[\"form\"] == \"10-K\")&(df_10K_copy[\"qtrs\"] == \"4\")&(df_all_10K[\"cik-fy\"].isin(df_10K_cik_missing[\"cik-fy\"]))&(df_all_10K[\"tag\"].str.contains(\"|\".join(df_gnr_tags[\"tag\"])))]\n",
    "    df_found_generic = df_all_10K_src[(df_all_10K_src[\"stmt\"] == var_FS)\n",
    "                                  &(df_all_10K_src[\"qtrs\"] == \"4\")&(df_all_10K_src[\"cfy\"].isin(df_10K_cik_missing[\"cfy\"]))\n",
    "                                  &(df_all_10K_src[\"tag\"].str.contains(\"|\".join(df_gnr_tags[\"tag\"])))]\n",
    "#df_found_generic.to_csv((folder_cos+\"10K\"+var_rel_met+\" 2 GENERIC FND.csv\"))\n",
    "#df_10K_fnd_gnr = df_found_generic[\"cik-fy\"]\n",
    "#df_10K_fnd_gnr.drop_duplicates(inplace=True)\n",
    "    df_found_generic.drop_duplicates(subset=[\"tag\"],inplace=True)\n",
    "    print(\"Found Generic \"+np.str(len(df_found_generic)))\n",
    "    df_found_generic.to_csv((folder_cos+\"ANNUAL \"+var_FS+\" \"+df_met_tags4[counter_met]+\" 2 GENERIC FND.csv\"))\n",
    "    \n",
    "    counter_met = counter_met + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance Sheet Cash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALANCE SHEET ENTRIES\n",
    "\n",
    "# Metric of Interest\n",
    "var_rel_met = \"CASH\"\n",
    "\n",
    "var_FS = var_BS\n",
    "\n",
    "# GET RELEVANT TAGS \n",
    "df_rel_tags = df_all_tags[\"tag\"][df_all_tags[\"metric\"] == var_rel_met]\n",
    "df_rel_tags.drop_duplicates(inplace=True)\n",
    "df_rel_tags = pd.DataFrame(df_rel_tags)\n",
    "\n",
    "# Delete Additional Tags\n",
    "df_addln_tags = pd.DataFrame()\n",
    "li_cash_tags = [\"MARKETABLESECURITIESCURRENT\",\"AVAILABLEFORSALESECURITIESCURRENT\",\"SHORTTERMINVESTMENTS\"]\n",
    "df_addln_tags = df_addln_tags.append(li_cash_tags,ignore_index=True)\n",
    "df_addln_tags.rename(columns={0:\"tag\"},inplace=True)\n",
    "df_rel_tags = df_rel_tags[~(df_rel_tags[\"tag\"].isin(df_addln_tags))]\n",
    "\n",
    "# GET THE IRRELEVANT TAGS\n",
    "df_irl_tags = df_all_tags[\"tag\"][~(df_all_tags[\"metric\"] == var_rel_met)]\n",
    "df_irl_tags.drop_duplicates(inplace=True)\n",
    "df_irl_tags = pd.DataFrame(df_irl_tags)\n",
    "\n",
    "# GET THE GENERIC TAGS\n",
    "df_gnr_tags = df_all_tags[\"tag_generic\"][df_all_tags[\"metric\"] == var_rel_met]\n",
    "df_gnr_tags.drop_duplicates(inplace=True)\n",
    "df_gnr_tags = pd.DataFrame(df_gnr_tags)\n",
    "df_gnr_tags.rename(columns={\"tag_generic\":\"tag\"},inplace=True)\n",
    "\n",
    "# PARE DOWN THE FINANCIAL STATEMENT DATA TO ONLY THOSE TAGS THAT ARE RELEVANT\n",
    "df_ANNUAL_temp = df_ANNUAL.copy()\n",
    "df_ANNUAL_rel = df_ANNUAL_temp[(df_ANNUAL_temp[\"stmt\"] == var_FS) &(df_ANNUAL_temp[\"tag\"].isin(df_rel_tags[\"tag\"]))\n",
    "                               ]\n",
    "\n",
    "df_ANNUAL_temp = pd.DataFrame()\n",
    "print((\"Number of Relevant Tagged Entries \"+np.str(len(df_ANNUAL_rel))))\n",
    "\n",
    "# RESET THE INDEX ON THE TAG DATAFRAME (# see INDEX_WOES notes)\n",
    "df_rel_tags2 = df_rel_tags.reset_index(level=0,drop=False)\n",
    "df_rel_tags2.drop(\"index\",axis=1,inplace=True)\n",
    "df_rel_tags4 = df_rel_tags2[\"tag\"]\n",
    "\n",
    "# GET ONLY THE COS AND FY THAT HAVE A RELEVANT (PRIOR) ENTRY\n",
    "# [Option 1] Pick from a prior file\n",
    "# df_rel_cos = pd.read_csv((folder_cos+\"Found Entries REVENU.csv\"),dtype=df_col_types)\n",
    "#or\n",
    "# [Option 2] Pick from current set of entries \n",
    "df_ANNUAL_temp = df_ANNUAL_rel.copy()\n",
    "df_rel_cos = df_ANNUAL_temp[[\"cfy\"]]\n",
    "df_rel_cos.drop_duplicates(subset=[\"cfy\"],inplace=True)\n",
    "df_ANNUAL_temp = pd.DataFrame()\n",
    "df_rel_cos_temp = df_rel_cos.copy()\n",
    "print((\"Number of Relevant Co-FY Combos \"+np.str(len(df_rel_cos_temp))))\n",
    "\n",
    "# Create a copy of the relevant entries\n",
    "df_ANNUAL_rcop = df_ANNUAL_rel.copy()\n",
    "\n",
    "df_entries_temp = pd.DataFrame()\n",
    "df_cosfy_tagfound = pd.DataFrame()\n",
    "df_cosfy_alltagfound = pd.DataFrame()\n",
    "df_cf_list = pd.DataFrame()\n",
    "counter_tag = 0\n",
    "\n",
    "while counter_tag < len(df_rel_tags4):\n",
    "    \n",
    "    df_entries_temp = df_ANNUAL_rcop[df_ANNUAL_rcop[\"cfy\"].isin(df_rel_cos_temp[\"cfy\"])]\n",
    "    \n",
    "    df_addln_tags = pd.DataFrame()\n",
    "    li_cash_tags = [\"MARKETABLESECURITIESCURRENT\",\"AVAILABLEFORSALESECURITIESCURRENT\",\"SHORTTERMINVESTMENTS\"]\n",
    "    df_addln_tags = df_addln_tags.append(li_cash_tags,ignore_index=True)\n",
    "    li_current_tag = pd.Series(df_rel_tags4[counter_tag])\n",
    "    df_addln_tags = df_addln_tags.append(li_current_tag,ignore_index=True)\n",
    "    df_addln_tags.rename(columns={0:\"tag\"},inplace=True)\n",
    "    \n",
    "    df_cosfy_tagfound = df_entries_temp[(df_entries_temp[\"tag\"].isin(df_addln_tags[\"tag\"]))]\n",
    "    \n",
    "    df_cosfy_alltagfound = df_cosfy_alltagfound.append(df_cosfy_tagfound,ignore_index=False)\n",
    "    \n",
    "    df_cf_list = df_cosfy_tagfound[[\"cfy\"]]\n",
    "    df_cf_list.drop_duplicates()\n",
    "    df_rel_cos_temp = df_rel_cos_temp[~(df_rel_cos_temp[\"cfy\"].isin(df_cf_list[\"cfy\"]))]\n",
    "    \n",
    "    print((df_rel_tags4[counter_tag]+ \" entries \"+np.str(len(df_cosfy_tagfound))))\n",
    " \n",
    "    counter_tag = counter_tag + 1\n",
    "\n",
    "\n",
    "# GET THE INDUSTRY AND THE SECTOR\n",
    "df_cik_sic_align = pd.read_csv((folder_mai+\"cik_sic_align.csv\"),dtype=df_col_types)\n",
    "df_sic_data = df_cik_sic_align[[\"sic\",\"Office\",\"Industry Title\"]] \n",
    "df_sic_data.drop_duplicates(subset=\"sic\",inplace=True)\n",
    "\n",
    "df_cosfy_alltagfound = pd.merge(df_cosfy_alltagfound,df_currency,left_on=\"uom\",right_on=\"Currency\",how=\"left\")\n",
    "df_cosfy_alltagfound[\"value Bn USD\"] = df_cosfy_alltagfound[\"value\"] / df_cosfy_alltagfound[\"inUSD\"] / 1000000000\n",
    "\n",
    "# MERGE THE RELEVANT ENTRIES WITH THE INDUSTRY AND SECTOR\n",
    "df_10K_met_found = pd.merge(df_cosfy_alltagfound,df_sic_data,on=\"sic\",how=\"left\")\n",
    "\n",
    "print(\"Entries Found \"+np.str(len(df_10K_met_found)))\n",
    "df_10K_met_found.to_csv((folder_cos+\"ANNUAL \"+var_FS+\" \"+var_rel_met+\" 1 FOUND.csv\"))\n",
    "\n",
    "df_10K_fnd_cik_fy = df_10K_met_found[\"cfy\"]\n",
    "df_10K_fnd_cik_fy.drop_duplicates(inplace=True)\n",
    "df_10K_fnd_cik_fy = pd.DataFrame(df_10K_fnd_cik_fy)\n",
    "print(\"CIK-FY Tag Found \"+np.str(len(df_10K_fnd_cik_fy)))\n",
    "\n",
    "df_10K_all_cik_fy = df_ANNUAL[\"cfy\"]\n",
    "df_10K_all_cik_fy.drop_duplicates(inplace=True)\n",
    "df_10K_all_cik_fy = pd.DataFrame(df_10K_all_cik_fy)\n",
    "print(\"CIK-FY All \"+np.str(len(df_10K_all_cik_fy)))\n",
    "\n",
    "df_10K_cik_missing = df_10K_all_cik_fy[~(df_10K_all_cik_fy[\"cfy\"].isin(df_10K_fnd_cik_fy[\"cfy\"]))]\n",
    "print(\"CIK-FY Missing \"+np.str(len(df_10K_cik_missing)))\n",
    "\n",
    "# Found Generic Tag\n",
    "df_all_10K_src = df_ANNUAL.copy()\n",
    "#df_found_generic = df_all_10K[(df_10K_copy[\"stmt\"] == var_IS)&(df_10K_copy[\"form\"] == \"10-K\")&(df_10K_copy[\"qtrs\"] == \"4\")&(df_all_10K[\"cik-fy\"].isin(df_10K_cik_missing[\"cik-fy\"]))&(df_all_10K[\"tag\"].str.contains(\"|\".join(df_gnr_tags[\"tag\"])))]\n",
    "df_found_generic = df_all_10K_src[(df_all_10K_src[\"stmt\"] == var_FS)\n",
    "                                  &(df_all_10K_src[\"cfy\"].isin(df_10K_cik_missing[\"cfy\"]))\n",
    "                                  &(df_all_10K_src[\"tag\"].str.contains(\"|\".join(df_gnr_tags[\"tag\"])))]\n",
    "#df_found_generic.to_csv((folder_cos+\"10K\"+var_rel_met+\" 2 GENERIC FND.csv\"))\n",
    "#df_10K_fnd_gnr = df_found_generic[\"cik-fy\"]\n",
    "#df_10K_fnd_gnr.drop_duplicates(inplace=True)\n",
    "df_found_generic.drop_duplicates(subset=[\"tag\"],inplace=True)\n",
    "print(\"Found Generic \"+np.str(len(df_found_generic)))\n",
    "df_found_generic.to_csv((folder_cos+\"ANNUAL \"+var_FS+\" \"+var_rel_met+\" 2 GENERIC FND.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cash Flow Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_FS = var_CF\n",
    "\n",
    "# GET METRICs \n",
    "df_met_tags = df_all_tags[\"metric\"][(df_all_tags[\"stmt\"] == var_FS)]\n",
    "df_met_tags.drop_duplicates(inplace=True)\n",
    "df_met_tags = pd.DataFrame(df_met_tags)\n",
    "\n",
    "df_met_tags2 = df_met_tags.reset_index(level=0,drop=False)\n",
    "df_met_tags2.drop(\"index\",axis=1,inplace=True)\n",
    "df_met_tags4 = df_met_tags2[\"metric\"]\n",
    "\n",
    "df_all_tags_copy = df_all_tags.copy()\n",
    "counter_met = 0\n",
    "\n",
    "while counter_met < len(df_met_tags4):\n",
    "    \n",
    "# GET RELEVANT TAGS    \n",
    "    df_rel_tags = df_all_tags_copy[(df_all_tags_copy[\"metric\"] == df_met_tags4[counter_met])&((df_all_tags_copy[\"stmt\"] == var_FS))]\n",
    "    df_rel_tags.drop_duplicates(inplace=True)\n",
    "    df_rel_tags = pd.DataFrame(df_rel_tags)\n",
    "    print((\"Tags in Metric \"+df_met_tags4[counter_met]+\" are \"+np.str(len(df_rel_tags))))\n",
    "\n",
    "# PARE DOWN THE FINANCIAL STATEMENT DATA TO ONLY THOSE TAGS THAT ARE RELEVANT\n",
    "    df_ANNUAL_temp = df_ANNUAL.copy()\n",
    "    df_ANNUAL_rel = df_ANNUAL_temp[(df_ANNUAL_temp[\"stmt\"] == var_FS) &(df_ANNUAL_temp[\"tag\"].isin(df_rel_tags[\"tag\"]))\n",
    "                               &(df_ANNUAL_temp[\"qtrs\"] == \"4\")]\n",
    "\n",
    "    print((\"Entries with \"+df_met_tags4[counter_met]+\" relevant tags are \"+np.str(len(df_ANNUAL_rel))))\n",
    "    \n",
    "    # RESET THE INDEX ON THE TAG DATAFRAME (# see INDEX_WOES notes)\n",
    "    df_rel_tags2 = df_rel_tags.reset_index(level=0,drop=False)\n",
    "    df_rel_tags2.drop(\"index\",axis=1,inplace=True)\n",
    "    df_rel_tags4 = df_rel_tags2[\"tag\"]\n",
    "    \n",
    "    df_ANNUAL_temp = df_ANNUAL_rel.copy()\n",
    "    df_rel_cos = df_ANNUAL_temp[[\"cfy\"]]\n",
    "    df_rel_cos.drop_duplicates(subset=[\"cfy\"],inplace=True)\n",
    "    df_ANNUAL_temp = pd.DataFrame()\n",
    "    df_rel_cos_temp = df_rel_cos.copy()\n",
    "    print((\"Number of Relevant Co-FY Combos \"+np.str(len(df_rel_cos_temp))))\n",
    "    \n",
    "    # Create a copy of the relevant entries\n",
    "    df_ANNUAL_rcop = df_ANNUAL_rel.copy()\n",
    "\n",
    "    df_entries_temp = pd.DataFrame()\n",
    "    df_cosfy_tagfound = pd.DataFrame()\n",
    "    df_cosfy_alltagfound = pd.DataFrame()\n",
    "    df_cf_list = pd.DataFrame()\n",
    "    counter_tag = 0\n",
    "    \n",
    "    while counter_tag < len(df_rel_tags4):\n",
    "    \n",
    "        df_entries_temp = df_ANNUAL_rcop[df_ANNUAL_rcop[\"cfy\"].isin(df_rel_cos_temp[\"cfy\"])]\n",
    "        df_cosfy_tagfound = df_entries_temp[(df_entries_temp[\"tag\"] == df_rel_tags4[counter_tag])]\n",
    "    \n",
    "        df_cosfy_alltagfound = df_cosfy_alltagfound.append(df_cosfy_tagfound,ignore_index=False)\n",
    "    \n",
    "        df_cf_list = df_cosfy_tagfound[[\"cfy\"]]\n",
    "        df_cf_list.drop_duplicates()\n",
    "#   df_cf_list[\"cik-fy\"] = df_cf_list[\"cik\"] + \"-\" + df_cf_list[\"fy\"]    \n",
    "        df_rel_cos_temp = df_rel_cos_temp[~(df_rel_cos_temp[\"cfy\"].isin(df_cf_list[\"cfy\"]))]\n",
    "    \n",
    "        print((df_rel_tags4[counter_tag]+ \" entries \"+np.str(len(df_cosfy_tagfound))))\n",
    "    \n",
    "        counter_tag = counter_tag + 1\n",
    "\n",
    "    df_cosfy_alltagfound = pd.merge(df_cosfy_alltagfound,df_currency,left_on=\"uom\",right_on=\"Currency\",how=\"left\")\n",
    "    df_cosfy_alltagfound[\"value Bn USD\"] = df_cosfy_alltagfound[\"value\"] / df_cosfy_alltagfound[\"inUSD\"] / 1000000000\n",
    "\n",
    "    # MERGE THE RELEVANT ENTRIES WITH THE INDUSTRY AND SECTOR\n",
    "    df_10K_met_found = pd.merge(df_cosfy_alltagfound,df_sic_data,on=\"sic\",how=\"left\")\n",
    "    \n",
    "    print(\"Entries Found \"+np.str(len(df_10K_met_found)))\n",
    "    df_10K_met_found.to_csv((folder_cos+\"ANNUAL \"+var_FS+\" \"+df_met_tags4[counter_met]+\" 1 FOUND.csv\"))\n",
    "\n",
    "    df_10K_fnd_cik_fy = df_10K_met_found[\"cfy\"]\n",
    "    df_10K_fnd_cik_fy.drop_duplicates(inplace=True)\n",
    "    df_10K_fnd_cik_fy = pd.DataFrame(df_10K_fnd_cik_fy)\n",
    "    print(\"CIK-FY Tag Found \"+np.str(len(df_10K_fnd_cik_fy)))\n",
    "\n",
    "    df_10K_all_cik_fy = df_ANNUAL[\"cfy\"]\n",
    "    df_10K_all_cik_fy.drop_duplicates(inplace=True)\n",
    "    df_10K_all_cik_fy = pd.DataFrame(df_10K_all_cik_fy)\n",
    "    print(\"CIK-FY All \"+np.str(len(df_10K_all_cik_fy)))\n",
    "\n",
    "    df_10K_cik_missing = df_10K_all_cik_fy[~(df_10K_all_cik_fy[\"cfy\"].isin(df_10K_fnd_cik_fy[\"cfy\"]))]\n",
    "    print(\"CIK-FY Missing \"+np.str(len(df_10K_cik_missing)))\n",
    "    \n",
    "    # GET THE IRRELEVANT TAGS\n",
    "    df_irl_tags = df_all_tags[\"tag\"][~(df_all_tags[\"metric\"] == df_met_tags4[counter_met])&(df_all_tags[\"stmt\"] == var_FS)]\n",
    "    df_irl_tags.drop_duplicates(inplace=True)\n",
    "    df_irl_tags = pd.DataFrame(df_irl_tags)\n",
    "\n",
    "# GET THE GENERIC TAGS\n",
    "    df_gnr_tags = df_all_tags_copy[\"tag_generic\"][(df_all_tags_copy[\"metric\"] == df_met_tags4[counter_met])&((df_all_tags_copy[\"stmt\"] == var_FS))]\n",
    "    df_gnr_tags.drop_duplicates(inplace=True)\n",
    "    df_gnr_tags = pd.DataFrame(df_gnr_tags)\n",
    "    df_gnr_tags.rename(columns={\"tag_generic\":\"tag\"},inplace=True)\n",
    "\n",
    "# Found Generic Tag\n",
    "    df_all_10K_src = df_ANNUAL.copy()\n",
    "#df_found_generic = df_all_10K[(df_10K_copy[\"stmt\"] == var_IS)&(df_10K_copy[\"form\"] == \"10-K\")&(df_10K_copy[\"qtrs\"] == \"4\")&(df_all_10K[\"cik-fy\"].isin(df_10K_cik_missing[\"cik-fy\"]))&(df_all_10K[\"tag\"].str.contains(\"|\".join(df_gnr_tags[\"tag\"])))]\n",
    "    df_found_generic = df_all_10K_src[(df_all_10K_src[\"stmt\"] == var_FS)\n",
    "                                  &(df_all_10K_src[\"qtrs\"] == \"4\")&(df_all_10K_src[\"cfy\"].isin(df_10K_cik_missing[\"cfy\"]))\n",
    "                                  &(df_all_10K_src[\"tag\"].str.contains(\"|\".join(df_gnr_tags[\"tag\"])))]\n",
    "#df_found_generic.to_csv((folder_cos+\"10K\"+var_rel_met+\" 2 GENERIC FND.csv\"))\n",
    "#df_10K_fnd_gnr = df_found_generic[\"cik-fy\"]\n",
    "#df_10K_fnd_gnr.drop_duplicates(inplace=True)\n",
    "    df_found_generic.drop_duplicates(subset=[\"tag\"],inplace=True)\n",
    "    print(\"Found Generic \"+np.str(len(df_found_generic)))\n",
    "    df_found_generic.to_csv((folder_cos+\"ANNUAL \"+var_FS+\" \"+df_met_tags4[counter_met]+\" 2 GENERIC FND.csv\"))\n",
    "    \n",
    "    counter_met = counter_met + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASH FLOW NET CASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_FS = var_CF\n",
    "var_rel_met = \"NETCASH\"\n",
    "\n",
    "# GET METRICs \n",
    "df_met_tags = df_all_tags[\"metric\"][(df_all_tags[\"stmt\"] == var_FS)]\n",
    "df_met_tags.drop_duplicates(inplace=True)\n",
    "df_met_tags = pd.DataFrame(df_met_tags)\n",
    "\n",
    "df_met_tags2 = df_met_tags.reset_index(level=0,drop=False)\n",
    "df_met_tags2.drop(\"index\",axis=1,inplace=True)\n",
    "df_met_tags4 = df_met_tags2[\"metric\"]\n",
    "\n",
    "df_all_tags_copy = df_all_tags.copy()\n",
    "counter_met = 0\n",
    "    \n",
    "# GET RELEVANT TAGS    \n",
    "df_rel_tags = df_all_tags_copy[(df_all_tags_copy[\"metric\"] == var_rel_met)&((df_all_tags_copy[\"stmt\"] == var_FS))]\n",
    "df_rel_tags.drop_duplicates(inplace=True)\n",
    "df_rel_tags = pd.DataFrame(df_rel_tags)\n",
    "print((\"Tags in Metric \"+var_rel_met+\" are \"+np.str(len(df_rel_tags))))\n",
    "\n",
    "# PARE DOWN THE FINANCIAL STATEMENT DATA TO ONLY THOSE TAGS THAT ARE RELEVANT\n",
    "df_ANNUAL_temp = df_ANNUAL.copy()\n",
    "df_ANNUAL_rel = df_ANNUAL_temp[(df_ANNUAL_temp[\"stmt\"] == var_FS) &(df_ANNUAL_temp[\"tag\"].isin(df_rel_tags[\"tag\"]))\n",
    "                               &(df_ANNUAL_temp[\"qtrs\"] == \"4\")]\n",
    "\n",
    "print((\"Entries with \"+var_rel_met+\" relevant tags are \"+np.str(len(df_ANNUAL_rel))))\n",
    "    \n",
    "    # RESET THE INDEX ON THE TAG DATAFRAME (# see INDEX_WOES notes)\n",
    "df_rel_tags2 = df_rel_tags.reset_index(level=0,drop=False)\n",
    "df_rel_tags2.drop(\"index\",axis=1,inplace=True)\n",
    "df_rel_tags4 = df_rel_tags2[\"tag\"]\n",
    "    \n",
    "df_ANNUAL_temp = df_ANNUAL_rel.copy()\n",
    "df_rel_cos = df_ANNUAL_temp[[\"cfy\"]]\n",
    "df_rel_cos.drop_duplicates(subset=[\"cfy\"],inplace=True)\n",
    "df_ANNUAL_temp = pd.DataFrame()\n",
    "df_rel_cos_temp = df_rel_cos.copy()\n",
    "print((\"Number of Relevant Co-FY Combos \"+np.str(len(df_rel_cos_temp))))\n",
    "    \n",
    "# Create a copy of the relevant entries\n",
    "df_cosfy_tagfound = pd.DataFrame()\n",
    "df_cosfy_alltagfound = pd.DataFrame()\n",
    "df_cf_list = pd.DataFrame()\n",
    "counter_tag = 0\n",
    "df_ANNUAL_rcop = df_ANNUAL_rel.copy()\n",
    "df_ANNUAL_rel.sort_values(by=\"cfy\",ascending=False,inplace=True)\n",
    "df_rel_tags4 = pd.DataFrame()    \n",
    "df_rel_tags4 = pd.Series([\"NETCASHPROVIDEDBYUSEDINOPERATINGACTIVITIES\",\"NETCASHPROVIDEDBYUSEDINOPERATINGACTIVITIESCONTINUINGOPERATIONS\"])\n",
    "df_rel_tags4 = pd.DataFrame(df_rel_tags4)\n",
    "df_rel_tags4.rename(columns={0:\"tag\"},inplace=True)  \n",
    "#df_entries_temp = df_ANNUAL_rcop[df_ANNUAL_rcop[\"cik-cfy\"].isin(df_rel_cos_temp[\"cik-cfy\"])]\n",
    "df_cosfy_tagfound = df_ANNUAL_rcop[(df_ANNUAL_rcop[\"tag\"].isin(df_rel_tags4[\"tag\"]))&df_ANNUAL_rcop[\"cfy\"].isin(df_rel_cos_temp[\"cfy\"])]\n",
    "\n",
    "df_cosfy_tagfound_copy = df_cosfy_tagfound.copy()\n",
    "\n",
    "df_cosfy_tagfound_copy.sort_values(by=[\"cfy\",\"value\"],inplace=True)\n",
    "df_cosfy_tagfound_copy.drop_duplicates(subset=\"cfy\",inplace=True)\n",
    "\n",
    "df_cosfy_alltagfound = df_cosfy_alltagfound.append(df_cosfy_tagfound_copy,ignore_index=False)\n",
    "print((var_rel_met+ \" OPRT entries \"+np.str(len(df_cosfy_tagfound))))\n",
    "\n",
    "df_ANNUAL_rcop = df_ANNUAL_rel.copy()\n",
    "df_rel_tags4 = pd.DataFrame()\n",
    "df_rel_tags4 = pd.Series([\"NETCASHPROVIDEDBYUSEDININVESTINGACTIVITIES\",\"NETCASHPROVIDEDBYUSEDININVESTINGACTIVITIESCONTINUINGOPERATIONS\"])\n",
    "df_rel_tags4 = pd.DataFrame(df_rel_tags4)\n",
    "df_rel_tags4.rename(columns={0:\"tag\"},inplace=True)  \n",
    "df_cosfy_tagfound = df_ANNUAL_rcop[(df_ANNUAL_rcop[\"tag\"].isin(df_rel_tags4[\"tag\"]))&df_ANNUAL_rcop[\"cfy\"].isin(df_rel_cos_temp[\"cfy\"])]\n",
    "df_cosfy_tagfound_copy = df_cosfy_tagfound.copy()\n",
    "\n",
    "df_cosfy_tagfound_copy.sort_values(by=[\"cfy\",\"value\"],inplace=True)\n",
    "df_cosfy_tagfound_copy.drop_duplicates(subset=\"cfy\",inplace=True)\n",
    "\n",
    "df_cosfy_alltagfound = df_cosfy_alltagfound.append(df_cosfy_tagfound_copy,ignore_index=False)\n",
    "print((var_rel_met+ \" INVST entries \"+np.str(len(df_cosfy_tagfound))))\n",
    "\n",
    "df_ANNUAL_rcop = df_ANNUAL_rel.copy()\n",
    "df_rel_tags4 = pd.DataFrame()\n",
    "df_rel_tags4 = pd.Series([\"NETCASHPROVIDEDBYUSEDINFINANCINGACTIVITIES\",\"NETCASHPROVIDEDBYUSEDINFINANCINGACTIVITIESCONTINUINGOPERATIONS\"])\n",
    "df_rel_tags4 = pd.DataFrame(df_rel_tags4)\n",
    "df_rel_tags4.rename(columns={0:\"tag\"},inplace=True)  \n",
    "df_cosfy_tagfound = df_ANNUAL_rcop[(df_ANNUAL_rcop[\"tag\"].isin(df_rel_tags4[\"tag\"]))&df_ANNUAL_rcop[\"cfy\"].isin(df_rel_cos_temp[\"cfy\"])]\n",
    "df_cosfy_tagfound_copy = df_cosfy_tagfound.copy()\n",
    "\n",
    "df_cosfy_tagfound_copy.sort_values(by=[\"cfy\",\"value\"],inplace=True)\n",
    "df_cosfy_tagfound_copy.drop_duplicates(subset=\"cfy\",inplace=True)\n",
    "\n",
    "df_cosfy_alltagfound = df_cosfy_alltagfound.append(df_cosfy_tagfound_copy,ignore_index=False)\n",
    "print((var_rel_met+ \" FINANC entries \"+np.str(len(df_cosfy_tagfound))))\n",
    "\n",
    "df_cosfy_alltagfound = pd.merge(df_cosfy_alltagfound,df_currency,left_on=\"uom\",right_on=\"Currency\",how=\"left\")\n",
    "df_cosfy_alltagfound[\"value Bn USD\"] = df_cosfy_alltagfound[\"value\"] / df_cosfy_alltagfound[\"inUSD\"] / 1000000000\n",
    "\n",
    "# MERGE THE RELEVANT ENTRIES WITH THE INDUSTRY AND SECTOR\n",
    "df_10K_met_found = pd.merge(df_cosfy_alltagfound,df_sic_data,on=\"sic\",how=\"left\")\n",
    "    \n",
    "print(\"Entries Found \"+np.str(len(df_10K_met_found)))\n",
    "df_10K_met_found.to_csv((folder_cos+\"ANNUAL \"+var_FS+\" \"+var_rel_met+\" 1 FOUND.csv\"))\n",
    "\n",
    "df_10K_fnd_cik_fy = df_10K_met_found[\"cfy\"]\n",
    "df_10K_fnd_cik_fy.drop_duplicates(inplace=True)\n",
    "df_10K_fnd_cik_fy = pd.DataFrame(df_10K_fnd_cik_fy)\n",
    "print(\"CIK-FY Tag Found \"+np.str(len(df_10K_fnd_cik_fy)))\n",
    "\n",
    "df_10K_all_cik_fy = df_ANNUAL[\"cfy\"]\n",
    "df_10K_all_cik_fy.drop_duplicates(inplace=True)\n",
    "df_10K_all_cik_fy = pd.DataFrame(df_10K_all_cik_fy)\n",
    "print(\"CIK-FY All \"+np.str(len(df_10K_all_cik_fy)))\n",
    "\n",
    "df_10K_cik_missing = df_10K_all_cik_fy[~(df_10K_all_cik_fy[\"cfy\"].isin(df_10K_fnd_cik_fy[\"cfy\"]))]\n",
    "print(\"CIK-FY Missing \"+np.str(len(df_10K_cik_missing)))\n",
    "    \n",
    "    # GET THE IRRELEVANT TAGS\n",
    "df_irl_tags = df_all_tags[\"tag\"][~(df_all_tags[\"metric\"] == var_rel_met)&(df_all_tags[\"stmt\"] == var_FS)]\n",
    "df_irl_tags.drop_duplicates(inplace=True)\n",
    "df_irl_tags = pd.DataFrame(df_irl_tags)\n",
    "\n",
    "# GET THE GENERIC TAGS\n",
    "df_gnr_tags = df_all_tags[\"tag_generic\"][(df_all_tags[\"metric\"] == var_rel_met)&((df_all_tags[\"stmt\"] == var_FS))]\n",
    "df_gnr_tags.drop_duplicates(inplace=True)\n",
    "df_gnr_tags = pd.DataFrame(df_gnr_tags)\n",
    "df_gnr_tags.rename(columns={\"tag_generic\":\"tag\"},inplace=True)\n",
    "\n",
    "# Found Generic Tag\n",
    "df_all_10K_src = df_ANNUAL.copy()\n",
    "#df_found_generic = df_all_10K[(df_10K_copy[\"stmt\"] == var_IS)&(df_10K_copy[\"form\"] == \"10-K\")&(df_10K_copy[\"qtrs\"] == \"4\")&(df_all_10K[\"cik-fy\"].isin(df_10K_cik_missing[\"cik-fy\"]))&(df_all_10K[\"tag\"].str.contains(\"|\".join(df_gnr_tags[\"tag\"])))]\n",
    "df_found_generic = df_all_10K_src[(df_all_10K_src[\"stmt\"] == var_FS)\n",
    "                                  &(df_all_10K_src[\"qtrs\"] == \"4\")&(df_all_10K_src[\"cfy\"].isin(df_10K_cik_missing[\"cfy\"]))\n",
    "                                  &(df_all_10K_src[\"tag\"].str.contains(\"|\".join(df_gnr_tags[\"tag\"])))]\n",
    "#df_found_generic.to_csv((folder_cos+\"10K\"+var_rel_met+\" 2 GENERIC FND.csv\"))\n",
    "#df_10K_fnd_gnr = df_found_generic[\"cik-fy\"]\n",
    "#df_10K_fnd_gnr.drop_duplicates(inplace=True)\n",
    "df_found_generic.drop_duplicates(subset=[\"tag\"],inplace=True)\n",
    "print(\"Found Generic \"+np.str(len(df_found_generic)))\n",
    "df_found_generic.to_csv((folder_cos+\"ANNUAL \"+var_FS+\" \"+var_rel_met+\" 2 GENERIC FND.csv\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
